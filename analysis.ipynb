{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from pandas.core.window.indexers import BaseIndexer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "\n",
    "class CustomIndexer(BaseIndexer):\n",
    "    def get_window_bounds(self, num_values=0, min_periods=None, center=None, closed=None):\n",
    "        end = np.arange(0, num_values, dtype=\"int64\")\n",
    "        end += 4\n",
    "        start = end - 3\n",
    "\n",
    "        end = np.clip(end, 0, num_values)\n",
    "        start = np.clip(start, 0, num_values)\n",
    "\n",
    "        return start, end\n",
    "\n",
    "\n",
    "def concat_rows(df, n):\n",
    "    new_cols = [\n",
    "        f\"{col}{idx}\"\n",
    "        for idx in range(1, n + 1)\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    n_cols = len(df.columns)\n",
    "    new_df = pandas.DataFrame(\n",
    "        df.values.reshape([-1, n_cols * n]),\n",
    "        columns=new_cols\n",
    "    )\n",
    "    return new_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "filename = \"data/2021_LoL_esports_match_data_from_OraclesElixir_20210515.csv\"\n",
    "\n",
    "data = pandas.read_csv(filename)\n",
    "data = data.reindex(index=data.index[::-1]).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "team_columns = [\"date\", \"actual_result\", \"playerid\", \"gameid\", \"team\", \"gamelength\", \"result\", \"dragons\", \"barons\",\n",
    "                \"riftheralds\", \"towers\"]\n",
    "player_columns = [\"date\", \"player\", \"gameid\", \"kills\", \"deaths\", \"assists\", \"dpm\", \"damageshare\",\n",
    "                  \"damagetakenperminute\", \"wpm\",\n",
    "                  \"vspm\", \"earned gpm\", \"cspm\", \"csat10\", \"goldat10\", \"killsat10\", \"deathsat10\", \"assistsat10\",\n",
    "                  \"csat15\", \"goldat15\", \"killsat15\", \"deathsat15\", \"assistsat15\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "data = data.sort_values(by=[\"date\", \"team\"])\n",
    "data = data.reset_index(drop=True)\n",
    "data[\"actual_result\"] = data[\"result\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "indexer = CustomIndexer(window_size=1)\n",
    "\n",
    "player_data = (\n",
    "    data\n",
    "        .filter(player_columns)\n",
    "        .groupby(pandas.Grouper(key=\"player\"))\n",
    "        .rolling(window=indexer, min_periods=1, on=\"gameid\")\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"level_1\": \"id\"})\n",
    "        .sort_values(by=\"id\")\n",
    "        .reset_index()\n",
    "        .drop(columns=[\"index\", \"player\", \"id\", \"gameid\"])\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "team_data = (\n",
    "    data\n",
    "        .query(\"playerid > 10\")\n",
    "        .filter(team_columns)\n",
    "        .groupby(pandas.Grouper(key=\"team\"))\n",
    "        .rolling(window=indexer, min_periods=1, on=\"actual_result\")\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"level_1\": \"id\"})\n",
    "        .sort_values(by=\"id\")\n",
    "        .reset_index()\n",
    "        .drop(columns=[\"index\", \"playerid\", \"id\"])\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "game_data_player = concat_rows(player_data, 10)\n",
    "game_data_team = concat_rows(team_data, 2)\n",
    "game_data_team.drop(columns=[\"actual_result2\", \"team1\", \"team2\"], inplace=True)\n",
    "\n",
    "game_data = (\n",
    "    pandas\n",
    "        .concat([game_data_team, game_data_player], axis=1)\n",
    "        .dropna()\n",
    ")\n",
    "\n",
    "\n",
    "game_result = game_data[\"actual_result1\"]\n",
    "game_data.drop(columns=[\"actual_result1\"], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6496124031007752\n",
      "0.5997482693517936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded = lab_enc.fit_transform(game_result)\n",
    "\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(\n",
    "    game_data, encoded, test_size=.33)\n",
    "model = RidgeClassifier().fit(trainX, trainY)\n",
    "\n",
    "print(model.score(trainX, trainY))\n",
    "print(model.score(testX, testY))\n",
    "\n",
    "\n",
    "# np.savetxt(\"aggr_data.csv\", data_aggr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "def create_dataset(input_data):\n",
    "    #random.shuffle(input_data)\n",
    "\n",
    "    target = torch.tensor(game_result, dtype=torch.long)\n",
    "    #print(input_data[0,:])\n",
    "    input_data = torch.tensor(input_data.values.astype(np.float32))\n",
    "   # input_data = torch.tensor(input_data, dtype=torch.float32)\n",
    "    #target = torch.tensor(input_data, dtype=torch.long)\n",
    "\n",
    "    dataset = TensorDataset(input_data, target)\n",
    "\n",
    "    # Compute batch sizes\n",
    "    size = len(input_data)\n",
    "    p1 = int(size * .8)\n",
    "    p2 = int(size * .1)\n",
    "    p3 = size - p1 - p2\n",
    "\n",
    "    train, validation, test = torch.utils.data.random_split(dataset, (p1, p2, p3))\n",
    "\n",
    "    tra_loader = DataLoader(train, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(validation, batch_size=128)\n",
    "    tes_loader = DataLoader(test, batch_size=128)\n",
    "\n",
    "\n",
    "\n",
    "    return tra_loader, val_loader, tes_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TestNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq = nn.Sequential(nn.Linear(input_size, 128),\n",
    "                        # nn.BatchNorm1d(64),\n",
    "                        # nn.ReLU(),\n",
    "                        # nn.Dropout(0.5),\n",
    "                        nn.Linear(128, 64),\n",
    "                        # nn.BatchNorm1d(32),\n",
    "                        # nn.ReLU(),\n",
    "                        # nn.Dropout(0.5),\n",
    "                        nn.Linear(64, 32),\n",
    "                        nn.Linear(32, 16),\n",
    "                        # nn.BatchNorm1d(16),\n",
    "                        # nn.ReLU(),\n",
    "                        nn.Linear(16, output_size))\n",
    "\n",
    "\n",
    "        def weight_init(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "        self.seq.apply(weight_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.seq(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def training(train: DataLoader, validation: DataLoader):\n",
    "    epochs = 150\n",
    "\n",
    "    model = TestNetwork(game_data.shape[1], 2).float()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    # model.train()\n",
    "    for e in range(epochs):\n",
    "        val_loss = []\n",
    "        val_acc = []\n",
    "        model.train()\n",
    "        for i, (inputs, target) in enumerate(train):\n",
    "            inputs, target = inputs.to(\"cpu\"), target.to(\"cpu\")\n",
    "            optimizer.zero_grad()\n",
    "            pred_target = model(inputs)\n",
    "            #pred_target = (pred_target > 0.5).float()\n",
    "            loss = criterion(pred_target, target.flatten())\n",
    "            loss.backward()\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            pred_target = pred_target.detach()\n",
    "            _, pred_target = torch.max(pred_target, dim=1)\n",
    "            correct = (pred_target == target.flatten()).sum().item()\n",
    "            acc = correct / len(target)\n",
    "            val_acc.append(acc)\n",
    "\n",
    "            optimizer.step()\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "\n",
    "        # print(\"TRAIN LOSS\", np.mean(val_loss))\n",
    "        # print(\"TRAIN ACC\", np.mean(val_acc))\n",
    "\n",
    "        val_loss = []\n",
    "        val_acc = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for i, (input, target) in enumerate(validation):\n",
    "                input, target = input.to(\"cpu\"), target.to(\"cpu\")\n",
    "                pred_target = model(input)\n",
    "\n",
    "                loss = criterion(pred_target, target.flatten().long())\n",
    "\n",
    "                #pred_target = pred_target[pred_target > 0.5]\n",
    "\n",
    "                _, pred_target = torch.max(pred_target, dim=1)\n",
    "                correct = (pred_target == target.flatten()).sum().item()\n",
    "                acc = correct / len(target)\n",
    "\n",
    "                val_loss.append(loss.item())\n",
    "                val_acc.append(acc)\n",
    "\n",
    "    return model\n",
    "\n",
    "def testing(model, test: DataLoader):\n",
    "    acc_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(test):\n",
    "            input, target = input.to(\"cpu\"), target.to(\"cpu\")\n",
    "            pred_target = model(input)\n",
    "\n",
    "            _, pred_target = torch.max(pred_target, dim=1)\n",
    "            correct = (pred_target == target.flatten()).sum().item()\n",
    "            acc = correct / len(target)\n",
    "            acc_list.append(acc)\n",
    "    print('test acc', np.mean(acc))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = create_dataset(game_data)\n",
    "model = training(train, validate)\n",
    "testing(model, test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}