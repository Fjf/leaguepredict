{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "from pandas.core.window.indexers import BaseIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "\n",
    "class CustomIndexer(BaseIndexer):\n",
    "    def get_window_bounds(self, num_values=0, min_periods=None, center=None, closed=None):\n",
    "        end = np.arange(0, num_values, dtype=\"int64\")\n",
    "        end += 4\n",
    "        start = end - 3\n",
    "\n",
    "        end = np.clip(end, 0, num_values)\n",
    "        start = np.clip(start, 0, num_values)\n",
    "\n",
    "        return start, end\n",
    "\n",
    "\n",
    "def concat_rows(df, n):\n",
    "    new_cols = [\n",
    "        f\"{col}{idx}\"\n",
    "        for idx in range(1, n + 1)\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    n_cols = len(df.columns)\n",
    "    new_df = pandas.DataFrame(\n",
    "        df.values.reshape([-1, n_cols * n]),\n",
    "        columns=new_cols\n",
    "    )\n",
    "    return new_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\duncan\\pycharmprojects\\leaguepredict\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3170: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#filename = \"data/2021_LoL_esports_match_data_from_OraclesElixir_20210515.csv\"\n",
    "\n",
    "\n",
    "path = r'C:\\Users\\duncan\\PycharmProjects\\leaguepredict\\data'  # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pandas.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "data = pandas.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "#data = pandas.read_csv(filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "team_columns = [\"date\", \"actual_result\", \"playerid\", \"gameid\", \"team\", \"gamelength\", \"result\", \"dragons\", \"barons\",\n",
    "                \"riftheralds\", \"towers\"]\n",
    "player_columns = [\"date\", \"player\", \"gameid\", \"kills\", \"deaths\", \"assists\", \"dpm\", \"damageshare\",\n",
    "                  \"damagetakenperminute\", \"wpm\",\n",
    "                  \"vspm\", \"earned gpm\", \"cspm\", \"csat10\", \"goldat10\", \"killsat10\", \"deathsat10\", \"assistsat10\",\n",
    "                  \"csat15\", \"goldat15\", \"killsat15\", \"deathsat15\", \"assistsat15\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "data = data.sort_values(by=[\"date\", \"playerid\"], ascending=[0, 1])\n",
    "data = data.reset_index(drop=True)\n",
    "data[\"actual_result\"] = data[\"result\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "indexer = CustomIndexer(window_size=1)\n",
    "\n",
    "player_data = (\n",
    "    data\n",
    "        .filter(player_columns)\n",
    "        .groupby(pandas.Grouper(key=\"player\"))\n",
    "        .rolling(window=indexer, min_periods=1, on=\"gameid\")\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"level_1\": \"id\"})\n",
    "        .sort_values(by=\"id\")\n",
    "        .reset_index()\n",
    "        .drop(columns=[\"index\", \"player\", \"id\", \"gameid\"])\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "team_data = (\n",
    "    data\n",
    "        .query(\"playerid > 10\")\n",
    "        .filter(team_columns)\n",
    "        .groupby(pandas.Grouper(key=\"team\"))\n",
    "        .rolling(window=indexer, min_periods=1, on=\"actual_result\")\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"level_1\": \"id\"})\n",
    "        .sort_values(by=\"id\")\n",
    "        .reset_index()\n",
    "        .drop(columns=[\"index\", \"playerid\", \"id\"])\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "game_data_player = concat_rows(player_data, 10)\n",
    "game_data_team = concat_rows(team_data, 2)\n",
    "game_data_team.drop(columns=[\"actual_result2\", \"team1\", \"team2\"], inplace=True)\n",
    "\n",
    "game_data = (\n",
    "    pandas\n",
    "        .concat([game_data_team, game_data_player], axis=1)\n",
    "        .dropna()\n",
    ")\n",
    "\n",
    "game_result = game_data[\"actual_result1\"]\n",
    "game_data.drop(columns=[\"actual_result1\"], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        0\n",
      "2        0\n",
      "3        1\n",
      "4        0\n",
      "        ..\n",
      "44206    0\n",
      "44207    1\n",
      "44208    1\n",
      "44209    1\n",
      "44210    0\n",
      "Name: actual_result1, Length: 35645, dtype: object\n",
      "0.6626329453144628\n",
      "0.6439683754144351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier, Ridge\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "print(game_result)\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "encoded = lab_enc.fit_transform(game_result)\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(\n",
    "    game_data, encoded, test_size=.33)\n",
    "model = RidgeClassifier()\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "print(model.score(trainX, trainY))\n",
    "print(model.score(testX, testY))\n",
    "print()\n",
    "\n",
    "# np.savetxt(\"aggr_data.csv\", data_aggr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import linear_model\n",
    "#\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn import utils\n",
    "#\n",
    "# print(game_result.mean())\n",
    "# lab_enc = preprocessing.LabelEncoder()\n",
    "# encoded = lab_enc.fit_transform(game_result)\n",
    "# print(encoded)\n",
    "# trainX, testX, trainY, testY = train_test_split(\n",
    "#     game_data, encoded, test_size=.33)\n",
    "# model = linear_model.LogisticRegression(fit_intercept=False, multi_class=\"ovr\")\n",
    "# model.fit(trainX, trainY)\n",
    "#\n",
    "# print(model.score(trainX, trainY))\n",
    "# print(model.score(testX, testY))\n",
    "#\n",
    "#\n",
    "# # np.savetxt(\"aggr_data.csv\", data_aggr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# iterable = sorted(zip(abs(model.coef_[0]), model.coef_[0], trainX.columns.values), key=lambda x: x[0])\n",
    "# sdata = np.array([a for a in reversed(iterable)])\n",
    "#\n",
    "# x = sdata[:, 2]\n",
    "# y = sdata[:, 1].astype(float)\n",
    "#\n",
    "# plt.bar(x[:10], y[:10])\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "#\n",
    "#\n",
    "# def create_dataset(input_data):\n",
    "#     #random.shuffle(input_data)\n",
    "#\n",
    "#     target = torch.tensor(game_result, dtype=torch.long)\n",
    "#     #print(input_data[0,:])\n",
    "#     input_data = torch.tensor(input_data.values.astype(np.float32))\n",
    "#     # input_data = torch.tensor(input_data, dtype=torch.float32)\n",
    "#     #target = torch.tensor(input_data, dtype=torch.long)\n",
    "#\n",
    "#     dataset = TensorDataset(input_data, target)\n",
    "#\n",
    "#     # Compute batch sizes\n",
    "#     size = len(input_data)\n",
    "#     p1 = int(size * .8)\n",
    "#     p2 = int(size * .1)\n",
    "#     p3 = size - p1 - p2\n",
    "#\n",
    "#     train, validation, test = torch.utils.data.random_split(dataset, (p1, p2, p3))\n",
    "#\n",
    "#     tra_loader = DataLoader(train, batch_size=64, shuffle=True)\n",
    "#     val_loader = DataLoader(validation, batch_size=128)\n",
    "#     tes_loader = DataLoader(test, batch_size=128)\n",
    "#\n",
    "#     return tra_loader, val_loader, tes_loader\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "#\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "#\n",
    "#\n",
    "# class TestNetwork(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super().__init__()\n",
    "#\n",
    "#         self.seq = nn.Sequential(nn.Linear(input_size, 128),\n",
    "#                                  # nn.BatchNorm1d(64),\n",
    "#                                  # nn.ReLU(),\n",
    "#                                  # nn.Dropout(0.5),\n",
    "#                                  nn.Linear(128, 64),\n",
    "#                                  # nn.BatchNorm1d(32),\n",
    "#                                  # nn.ReLU(),\n",
    "#                                  # nn.Dropout(0.5),\n",
    "#                                  nn.Linear(64, 32),\n",
    "#                                  nn.Linear(32, 16),\n",
    "#                                  # nn.BatchNorm1d(16),\n",
    "#                                  # nn.ReLU(),\n",
    "#                                  nn.Linear(16, output_size))\n",
    "#\n",
    "#         def weight_init(m):\n",
    "#             if isinstance(m, nn.Linear):\n",
    "#                 nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "#                 if m.bias is not None:\n",
    "#                     nn.init.zeros_(m.bias)\n",
    "#\n",
    "#         self.seq.apply(weight_init)\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         out = self.seq(x)\n",
    "#         return out\n",
    "#\n",
    "#\n",
    "# def training(train: DataLoader, validation: DataLoader):\n",
    "#     epochs = 150\n",
    "#\n",
    "#     model = TestNetwork(game_data.shape[1], 2).float()\n",
    "#     optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#\n",
    "#     # model.train()\n",
    "#     for e in range(epochs):\n",
    "#         val_loss = []\n",
    "#         val_acc = []\n",
    "#         model.train()\n",
    "#         for i, (inputs, target) in enumerate(train):\n",
    "#             inputs, target = inputs.to(\"cpu\"), target.to(\"cpu\")\n",
    "#             optimizer.zero_grad()\n",
    "#             pred_target = model(inputs)\n",
    "#             #pred_target = (pred_target > 0.5).float()\n",
    "#             loss = criterion(pred_target, target.flatten())\n",
    "#             loss.backward()\n",
    "#\n",
    "#             val_loss.append(loss.item())\n",
    "#\n",
    "#             pred_target = pred_target.detach()\n",
    "#             _, pred_target = torch.max(pred_target, dim=1)\n",
    "#             correct = (pred_target == target.flatten()).sum().item()\n",
    "#             acc = correct / len(target)\n",
    "#             val_acc.append(acc)\n",
    "#\n",
    "#             optimizer.step()\n",
    "#             #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "#\n",
    "#         # print(\"TRAIN LOSS\", np.mean(val_loss))\n",
    "#         # print(\"TRAIN ACC\", np.mean(val_acc))\n",
    "#\n",
    "#         val_loss = []\n",
    "#         val_acc = []\n",
    "#         with torch.no_grad():\n",
    "#             model.eval()\n",
    "#             for i, (input, target) in enumerate(validation):\n",
    "#                 input, target = input.to(\"cpu\"), target.to(\"cpu\")\n",
    "#                 pred_target = model(input)\n",
    "#\n",
    "#                 loss = criterion(pred_target, target.flatten().long())\n",
    "#\n",
    "#                 #pred_target = pred_target[pred_target > 0.5]\n",
    "#\n",
    "#                 _, pred_target = torch.max(pred_target, dim=1)\n",
    "#                 correct = (pred_target == target.flatten()).sum().item()\n",
    "#                 acc = correct / len(target)\n",
    "#\n",
    "#                 val_loss.append(loss.item())\n",
    "#                 val_acc.append(acc)\n",
    "#         print('val acc', np.mean(val_acc))\n",
    "#\n",
    "#     return model\n",
    "#\n",
    "#\n",
    "# def testing(model, test: DataLoader):\n",
    "#     acc_list = []\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for i, (input, target) in enumerate(test):\n",
    "#             input, target = input.to(\"cpu\"), target.to(\"cpu\")\n",
    "#             pred_target = model(input)\n",
    "#\n",
    "#             _, pred_target = torch.max(pred_target, dim=1)\n",
    "#             correct = (pred_target == target.flatten()).sum().item()\n",
    "#             acc = correct / len(target)\n",
    "#             acc_list.append(acc)\n",
    "#     print('test acc', np.mean(acc_list))\n",
    "#\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "# train, validate, test = create_dataset(game_data)\n",
    "# model = training(train, validate)\n",
    "# testing(model, test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "0.4843189452663713 (2.0647550746750336, 1.939183126509355)\n",
      "[0]\n",
      "0.362241718050103 (2.7605876136599106, 1.5679921818381986)\n",
      "[1]\n",
      "0.6896985312585743 (1.44990884375987, 3.2226724677004355)\n",
      "[1]\n",
      "0.5494513702350006 (1.8199972812376455, 2.2195162385059026)\n",
      "[1]\n",
      "0.5748396160301051 (1.7396156634194617, 2.352053572495618)\n",
      "[0]\n",
      "0.43752027535561283 (2.285608362234661, 1.7778418602238926)\n",
      "[0]\n",
      "0.33879908887127735 (2.9516017983741922, 1.512399609814391)\n",
      "[1]\n",
      "0.518738170521396 (1.9277548035358114, 2.077871002326101)\n",
      "[1]\n",
      "0.6451369146992983 (1.550058564647638, 2.8179882366536555)\n",
      "[1]\n",
      "0.6095066499365736 (1.6406711889100176, 2.5608630719001324)\n"
     ]
    }
   ],
   "source": [
    "def get_team(team_name):\n",
    "    teams = data.team.unique().astype(str).flatten()\n",
    "    if team_name in teams:\n",
    "        return team_name\n",
    "    matches = np.char.find(teams, team_name)\n",
    "    selection = teams[matches >= 0]\n",
    "    if len(selection) == 0:\n",
    "        print(\"No teams found with that name.\")\n",
    "        return None\n",
    "    if len(selection) > 1:\n",
    "        print(\"Multiple teams found: %s\" % \", \".join(selection))\n",
    "        return None\n",
    "    return selection[0]\n",
    "\n",
    "\n",
    "def get_something(all_data, blue_team=\"Fnatic\", red_team=\"Rogue\"):\n",
    "    blue_team = get_team(blue_team)\n",
    "    red_team = get_team(red_team)\n",
    "    if blue_team is None or red_team is None:\n",
    "        return\n",
    "\n",
    "    aggregation = None\n",
    "    for team in [blue_team, red_team]:\n",
    "        players = all_data.query(f\"team=='{team}'\").filter([\"player\"]).head(5)\n",
    "\n",
    "        for player in players.player.values:\n",
    "            new_player_data = (\n",
    "                all_data\n",
    "                    .filter(player_columns)\n",
    "                    .query(f\"player == '{player}'\")\n",
    "                    .head(3)\n",
    "                    .mean(axis=0)\n",
    "                    .to_frame()\n",
    "                    .transpose()\n",
    "            )\n",
    "\n",
    "            if aggregation is None:\n",
    "                aggregation = new_player_data\n",
    "            else:\n",
    "                aggregation = aggregation.append(new_player_data, ignore_index=True)\n",
    "\n",
    "    aggregation = aggregation.reindex(sorted(aggregation.columns), axis=1)\n",
    "    aggregation = concat_rows(aggregation, 10)\n",
    "    blue_team_data = (\n",
    "        all_data\n",
    "            .query(\"playerid > 10\")\n",
    "            .query(f\"team=='{blue_team}'\")\n",
    "            .filter(team_columns)\n",
    "            .head(3)\n",
    "            .rolling(3, on=\"actual_result\")\n",
    "            .mean()\n",
    "            .tail(1)\n",
    "    )\n",
    "    red_team_data = (\n",
    "        all_data\n",
    "            .query(\"playerid > 10\")\n",
    "            .query(f\"team=='{red_team}'\")\n",
    "            .filter(team_columns)\n",
    "            .head(3)\n",
    "            .rolling(3, on=\"actual_result\")\n",
    "            .mean()\n",
    "            .tail(1)\n",
    "    )\n",
    "    new_team_data = blue_team_data.append(red_team_data, ignore_index=True)\n",
    "    new_team_data = concat_rows(new_team_data, 2)\n",
    "\n",
    "    new_team_data.drop(columns=[\"actual_result2\", \"playerid1\", \"playerid2\"], inplace=True)\n",
    "\n",
    "    new_game_data = (\n",
    "        pandas\n",
    "            .concat([new_team_data, aggregation], axis=1)\n",
    "            .dropna()\n",
    "    )\n",
    "\n",
    "    new_game_data.drop(columns=[\"actual_result1\"], inplace=True)\n",
    "\n",
    "    return new_game_data\n",
    "\n",
    "matchups = [\n",
    "    (\"Schalke 04 Esports\", \"Excel Esports\"),\n",
    "    (\"Team Vitality\", \"Misfits Gaming\"),\n",
    "    (\"MAD Lions\", \"Astralis\"),\n",
    "    (\"G2 Esports\", \"SK Gaming\"),\n",
    "    (\"Fnatic\", \"Rogue\"),\n",
    "    (\"Astralis\", \"Schalke 04 Esports\"),\n",
    "    (\"Excel Esports\", \"Team Vitality\"),\n",
    "    (\"Rogue\", \"MAD Lions\"),\n",
    "    (\"Fnatic\", \"SK Gaming\"),\n",
    "    (\"Misfits Gaming\", \"G2 Esports\"),\n",
    "]\n",
    "\n",
    "for blue_team, red_team in matchups:\n",
    "\n",
    "    X = get_something(data, blue_team, red_team)\n",
    "    if X is not None:\n",
    "        print(model.predict(X))\n",
    "        prob = (model.decision_function(X)[0] + 1) / 2\n",
    "        odds = (1 / prob, 1 / (1 - prob))\n",
    "        print(prob, odds)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}